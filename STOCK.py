# -*- coding: utf-8 -*-
"""STOCKS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kmymXOy2IGH2Bib1HiAx-xa-EKVb1jpn
"""

import numpy as np
import warnings
from pandas_datareader import data as pdr
from pandas import read_csv

!pip install yfinance yahoo_fin

import yfinance as yf
import datetime as dt
from yahoo_fin import stock_info as si
import pandas as pd

from numpy import array
from numpy import hstack

from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
from keras.layers import SimpleRNN
from keras.layers import Dropout

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import math

import matplotlib
import matplotlib as mpl
import matplotlib.pyplot as plt

pd.set_option('display.max_rows', None)
warnings.filterwarnings("ignore")
yf.pdr_override()

num_of_years = 1
start = dt.date.today() - dt.timedelta(days = int(365.25*num_of_years))
end = dt.date.today()

tickers = si.tickers_dow()

"""Reading data"""

dataset = pdr.get_data_yahoo(tickers, start, end)['Adj Close']

def get_train_test(url, split_percent=0.8):
    df = read_csv(url, usecols=[1], engine='python')
    data = np.array(df.values.astype('float32'))
    scaler = MinMaxScaler(feature_range=(0, 1))
    data = scaler.fit_transform(data).flatten()
    n = len(data)
    # Point for splitting data into train and test
    split = int(n*split_percent)
    train_data = data[range(split)]
    test_data = data[split:]
    return train_data, test_data, data

stocks_url = 'https://query1.finance.yahoo.com/v7/finance/download/GOOG?period1=1110844800&period2=1678838400&interval=1d&events=history&includeAdjustedClose=true'

"""Punto 1.- Matrix

Punto 1.1.- Corralated portfolio Matrix
"""

stocks_returns = np.log(dataset/dataset.shift(1))

print('\nCorrelation Matrix')
corr_matrix = stocks_returns.corr()
print (corr_matrix)

def get_redundant_pairs(df):
  pairs_to_drop = set()
  cols = df.columns
  for i in range (0, df.shape[1]):
    for j in range(0, i+1):
      pairs_to_drop.add((cols[i], cols[j]))
  return pairs_to_drop

def get_top_abs_correlations(df):
  au_corr = df.corr().unstack()
  labels_to_drop = get_redundant_pairs(df)
  au_corr = au_corr.drop(labels = labels_to_drop).sort_values(ascending = False)
  return au_corr

print("\nTop Absolute Correlations")
print(get_top_abs_correlations(stocks_returns))

in_hor = ["AAPL", "MSFT", "V", "CRM", "AXP"]
in_ver = ["AAPL", "MSFT", "V", "CRM", "AXP"]

harvest = np.array([[1, 0.79, 0.71, 0.64, 0.67],
                    [0, 1, 0.63, 0, 0],
                    [0, 0, 1, 0, 0],
                    [0, 0.67, 0.60, 1, 0],
                    [0, 0.58, 0.72, 0.54, 1]])

fig, ax = plt.subplots()
im = ax.imshow(harvest)

ax.set_xticks(np.arange(len(in_hor)), labels = in_hor)
ax.set_yticks(np.arange(len(in_ver)), labels = in_ver)

plt.setp(ax.get_xticklabels(), rotation = 45, ha = "right", rotation_mode = "anchor")

for i in range(len(in_ver)):
  for j in range(len(in_hor)):
    text = ax.text(j, i, harvest[i, j], ha = "center", va = "center", color = "w")

ax.set_title(" CORRELATED PORTFOLIO ")
fig.tight_layout()
plt.show()

"""Punto 1.2.- Uncorralated portfolio Matrix"""

in_hor = ["DIS", "MRK", "CVX", "PG", "AMGN"]
in_ver = ["DIS", "MRK", "CVX", "PG", "AMGN"]

harvest = np.array([[1, 0.09, 0, 0.29, 0],
                    [0, 1, 0, 0.44, 0],
                    [0.38, 0.15, 1, 0.04, 0],
                    [0, 0, 0, 1, 0],
                    [0.22, 0.45, 0.16, 0.43, 1]])

fig, ax = plt.subplots()
im = ax.imshow(harvest)

ax.set_xticks(np.arange(len(in_hor)), labels = in_hor)
ax.set_yticks(np.arange(len(in_ver)), labels = in_ver)

plt.setp(ax.get_xticklabels(), rotation = 45, ha = "right", rotation_mode = "anchor")

for i in range(len(in_ver)):
  for j in range(len(in_hor)):
    text = ax.text(j, i, harvest[i, j], ha = "center", va = "center", color = "w")

ax.set_title(" UNCORRELATED PORTFOLIO ")
fig.tight_layout()
plt.show()

"""Punto 2.- One Stock predict"""

# Define the model

def create_RNN(hidden_units, dense_units, input_shape, activation):
    model = Sequential()
    model.add(SimpleRNN(hidden_units, input_shape=input_shape,
                        activation=activation[0]))
    model.add(Dense(units=dense_units, activation=activation[1]))
    model.compile(loss='mean_squared_error', optimizer='adam')
    return model

# hidden units tiene el valor de la longitud de la serie de datos.

def create_LSTM_RNN(hidden_units, dense_units, input_shape, activation, dropout):
    model = Sequential()
    model.add(LSTM(units = hidden_units, activation = activation[0], return_sequences = True, input_shape = input_shape))
    model.add(Dropout(dropout))
    model.add(LSTM(units = hidden_units, activation = activation[0], return_sequences = True))
    model.add(Dropout(dropout))
    model.add(LSTM(units = int(hidden_units*1.5), activation = activation[0], return_sequences = True))
    model.add(Dropout(dropout))
    model.add(LSTM(units = int(hidden_units*2.0), activation = activation[0]))
    model.add(Dropout(dropout))
    model.add(Dense(units=dense_units, activation=activation[1]))
    model.compile(loss='mean_squared_error', optimizer='adam')
    return model

# Reading the data

train_data, test_data, data = get_train_test(stocks_url) # Google stock

# Prepare the data

def get_XY(dat, time_steps, ticker_len):
    # Indices of target array
    Y_ind = np.arange(time_steps, len(dat), time_steps)
    Y = dat[Y_ind]
    # Prepare X
    rows_x = len(Y)
    X = dat[range(time_steps*rows_x)]
    X = np.reshape(X, (rows_x, time_steps, ticker_len))
    return X, Y

time_steps = 60
trainX, trainY = get_XY(train_data, time_steps, 1)
testX, testY = get_XY(test_data, time_steps, 1)

# Training the model

model = create_LSTM_RNN(60, 1, (time_steps,1), ['relu', 'relu'], 0.2)
model.fit(trainX, trainY, epochs=50, batch_size=32, verbose=2)

# Calculate mean square error

def print_error(trainY, testY, train_predict, test_predict):
    # Error of predictions
    train_rmse = math.sqrt(mean_squared_error(trainY, train_predict))
    test_rmse = math.sqrt(mean_squared_error(testY, test_predict))
    # Print RMSE
    print('Train RMSE: %.3f RMSE' % (train_rmse))
    print('Test RMSE: %.3f RMSE' % (test_rmse))

# Make predictions

train_predict = model.predict(trainX)
test_predict = model.predict(testX)

# Mean square error

print_error(trainY, testY, train_predict, test_predict)

# Plot the result
def plot_result(trainY, testY, train_predict, test_predict, sticker):
    actual = np.append(trainY, testY)
    predictions = np.append(train_predict, test_predict)
    rows = len(actual)
    plt.figure(figsize=(15, 6), dpi=80)
    plt.plot(range(rows), actual)
    plt.plot(range(rows), predictions)
    plt.axvline(x=len(trainY), color='r')
    plt.legend(['Actual', 'Predictions'])
    plt.xlabel('Observation number after given time steps')
    plt.ylabel('Stock Returns')
    plt.title('Actual and Predicted Values of ' + sticker + ' stock returns. The Red Line Separates The Training And Test Examples')
plot_result(trainY, testY, train_predict, test_predict, "Google")

"""Punto 3.- Multivariate Stock predict

Punto 3.1.- With Correlated portfolio Matrix
"""

# Reading and prepare the data

ticker_list = ("AAPL", "MSFT", "V", "CRM", "AXP")
ticker_len = len(ticker_list)

def get_train_test_tickers(tickers, num_of_years=1, split_percent=0.8):

    start = dt.date.today() - dt.timedelta(days = int(365.25*num_of_years))
    end = dt.date.today()
    df = pdr.get_data_yahoo(tickers, start, end)['Adj Close']
    pre_data = np.array(df.values.astype('float32'))
    data = pre_data.reshape(-1,len(tickers))
    scaler = MinMaxScaler(feature_range=(0, 1))
    data = scaler.fit_transform(data)
    n = len(data)
    # Point for splitting data into train and test
    split = int(n*split_percent)
    train_data = data[range(split)]
    test_data = data[split:]
    return train_data, test_data, data

train_data, test_data, data = get_train_test_tickers(ticker_list, 10, 0.8)

time_steps = 60
trainX, trainY = get_XY(train_data, time_steps, ticker_len)
testX, testY = get_XY(test_data, time_steps, ticker_len)

# Training the model

model = create_LSTM_RNN(60, ticker_len, (time_steps,ticker_len), ['relu', 'relu'], 0.2)
model.fit(trainX, trainY, epochs=50, batch_size=32, verbose=2)

# Make predictions

train_predict = model.predict(trainX)
test_predict = model.predict(testX)

# Mean square error

print_error(trainY, testY, train_predict, test_predict)

# Plot the result

plot_result(trainY[:,0], testY[:,0], train_predict[:,0], test_predict[:,0], ticker_list[0])
plot_result(trainY[:,1], testY[:,1], train_predict[:,1], test_predict[:,1], ticker_list[1])
plot_result(trainY[:,2], testY[:,2], train_predict[:,2], test_predict[:,2], ticker_list[2])
plot_result(trainY[:,3], testY[:,3], train_predict[:,3], test_predict[:,3], ticker_list[3])
plot_result(trainY[:,4], testY[:,4], train_predict[:,4], test_predict[:,4], ticker_list[4])

"""Punto 3.2.- With Uncorrelated portfolio Matrix"""

# Reading and prepare the data

ticker_list = ("DIS", "MRK", "CVX", "PG", "AMGN")
ticker_len = len(ticker_list)

train_data, test_data, data = get_train_test_tickers(ticker_list, 10, 0.8)

time_steps = 60
trainX, trainY = get_XY(train_data, time_steps, ticker_len)
testX, testY = get_XY(test_data, time_steps, ticker_len)

# Training the model

model = create_LSTM_RNN(60, ticker_len, (time_steps,ticker_len), ['relu', 'relu'], 0.2)
model.fit(trainX, trainY, epochs=50, batch_size=32, verbose=2)

# Make predictions

train_predict = model.predict(trainX)
test_predict = model.predict(testX)

# Mean square error

print_error(trainY, testY, train_predict, test_predict)

# Plot results

plot_result(trainY[:,0], testY[:,0], train_predict[:,0], test_predict[:,0], ticker_list[0])
plot_result(trainY[:,1], testY[:,1], train_predict[:,1], test_predict[:,1], ticker_list[1])
plot_result(trainY[:,2], testY[:,2], train_predict[:,2], test_predict[:,2], ticker_list[2])
plot_result(trainY[:,3], testY[:,3], train_predict[:,3], test_predict[:,3], ticker_list[3])
plot_result(trainY[:,4], testY[:,4], train_predict[:,4], test_predict[:,4], ticker_list[4])